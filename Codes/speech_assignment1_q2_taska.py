# -*- coding: utf-8 -*-
"""Speech_Assignment1_Q2_TaskA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Lv-Ijp5gP8DRkOKx7fQeG_jzPhHSqOFR

## **Using** **SVM**
"""

import os
import zipfile
import urllib.request
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import get_window
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report

!pip install soundata
!pip install soundata --quiet
import soundata
dataset_folder = "UrbanSound8K"

def download_and_extract_dataset():
    print("Initializing UrbanSound8K dataset with soundata...")
    dataset = soundata.initialize('urbansound8k', data_home=dataset_folder)

    if not os.path.exists(dataset_folder):
        print("Downloading UrbanSound8K dataset...")
        dataset.download()
        print("Download complete.")
    else:
        print("Dataset already exists. Skipping download.")

    return dataset

dataset = download_and_extract_dataset()

def load_audio(file_path, sr=22050):
    y, sr = librosa.load(file_path, sr=sr)
    return y, sr

def compute_spectrogram(y, sr, window_type, n_fft=2048, hop_length=512):
    window = get_window(window_type, n_fft)
    stft = librosa.stft(y, n_fft=n_fft, hop_length=hop_length, window=window)
    spectrogram = np.abs(stft)
    return spectrogram

def plot_spectrogram(spectrogram, title, sr, hop_length):
    plt.figure(figsize=(10, 4))
    librosa.display.specshow(librosa.amplitude_to_db(spectrogram, ref=np.max),
                             sr=sr, hop_length=hop_length, x_axis='time', y_axis='log')
    plt.colorbar(format='%+2.0f dB')
    plt.title(title)
    plt.show()

clip_ids = dataset.clip_ids
sample_clip = dataset.clip(clip_ids[0])
sample_file = sample_clip.audio_path

y, sr = load_audio(sample_file)

windows = ["hann", "hamming", "boxcar"]
for win in windows:
    spectrogram = compute_spectrogram(y, sr, window_type=win)
    plot_spectrogram(spectrogram, f"Spectrogram with {win} window", sr, hop_length=512)

def extract_features(y, sr, window_type, n_mfcc=13):
    spectrogram = compute_spectrogram(y, sr, window_type)
    mfccs = librosa.feature.mfcc(S=spectrogram, sr=sr, n_mfcc=n_mfcc)
    return np.mean(mfccs, axis=1)

X = []
y_labels = []
window_types = ["hann", "hamming", "boxcar"]

for clip_id in dataset.clip_ids[:100]:
    clip = dataset.clip(clip_id)
    file_path = clip.audio_path
    label = clip.tags.labels[0] if clip.tags.labels else 0

    y_audio, sr_audio = load_audio(file_path)

    for win in window_types:
        features = extract_features(y_audio, sr_audio, window_type=win)
        X.append(features)
        y_labels.append(label)

X = np.array(X)
y_labels = np.array(y_labels)

X_train, X_test, y_train, y_test = train_test_split(X, y_labels, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

classifier = SVC(kernel='linear')
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""## **Using** **CNN**"""

import librosa
import librosa.display
import soundata
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from scipy.signal import get_window

dataset_folder = "UrbanSound8K"

def download_and_extract_dataset():
    print("Initializing UrbanSound8K dataset with soundata...")
    dataset = soundata.initialize('urbansound8k', data_home=dataset_folder)

    if not os.path.exists(dataset_folder):
        print("Downloading UrbanSound8K dataset...")
        dataset.download()
        print("Download complete.")
    else:
        print("Dataset already exists. Skipping download.")

    return dataset

dataset = download_and_extract_dataset()

def load_audio(file_path, sr=22050):
    y, sr = librosa.load(file_path, sr=sr)
    return y, sr

n_fft = 4096

def compute_spectrogram(y, sr, window_type, hop_length=None):
    """Computes STFT-based spectrogram using a given windowing technique and adjusts time-frame dynamically."""

    if hop_length is None:
        hop_length = n_fft // 4

    window = get_window(window_type, n_fft)
    stft = librosa.stft(y, n_fft=n_fft, hop_length=hop_length, window=window)
    spectrogram = np.abs(stft)

    return spectrogram

all_time_frames = []

for clip_id in dataset.clip_ids[:300]:
    clip = dataset.clip(clip_id)
    file_path = clip.audio_path
    y_audio, sr_audio = load_audio(file_path)

    for win in ["hann", "hamming", "boxcar"]:
        spectrogram = compute_spectrogram(y_audio, sr_audio, window_type=win)
        all_time_frames.append(spectrogram.shape[1])

max_time_frames = min(max(all_time_frames), 200)

print(f"ðŸ“Œ Automatically set max_time_frames to: {max_time_frames}")

X = []
y_labels = []
window_types = ["hann", "hamming", "boxcar"]

for clip_id in dataset.clip_ids[:300]:
    clip = dataset.clip(clip_id)
    file_path = clip.audio_path
    label = clip.tags.labels[0] if clip.tags.labels else "unknown"

    y_audio, sr_audio = load_audio(file_path)

    for win in window_types:
        spectrogram = compute_spectrogram(y_audio, sr_audio, window_type=win)

        if spectrogram.shape[1] < max_time_frames:
            pad_width = max_time_frames - spectrogram.shape[1]
            spectrogram = np.pad(spectrogram, ((0, 0), (0, pad_width)), mode='constant')
        else:
            spectrogram = spectrogram[:, :max_time_frames]

        X.append(spectrogram)
        y_labels.append(label)

X = np.array(X)
y_labels = np.array(y_labels)

X = X / np.max(X)
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y_labels)
y_categorical = to_categorical(y_encoded)

X = X[..., np.newaxis]

X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)

def build_cnn_model(input_shape, num_classes):
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        BatchNormalization(),
        MaxPooling2D((2, 2)),

        Conv2D(64, (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D((2, 2)),

        Conv2D(128, (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D((2, 2)),

        Flatten(),
        Dense(256, activation='relu'),
        BatchNormalization(),
        Dropout(0.3),
        Dense(num_classes, activation='softmax')
    ])

    model.compile(optimizer=Adam(learning_rate=0.0005),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)

cnn_model = build_cnn_model(input_shape=X_train.shape[1:], num_classes=y_categorical.shape[1])
cnn_model.summary()

cnn_model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test), callbacks=[reduce_lr])

test_loss, test_acc = cnn_model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_acc:.2f}")

def plot_spectrogram(spectrogram, title, sr, hop_length):
    plt.figure(figsize=(10, 4))
    librosa.display.specshow(librosa.amplitude_to_db(spectrogram + 1e-10, ref=np.max),  # âœ… Fix colors
                             sr=sr, hop_length=hop_length, x_axis='time', y_axis='log')
    plt.colorbar(format='%+2.0f dB')
    plt.title(title)
    plt.show()

file_path = dataset.clip(dataset.clip_ids[0]).audio_path  # Select an example file
y, sr = load_audio(file_path)

for win in window_types:
    spectrogram = compute_spectrogram(y, sr, window_type=win)
    plot_spectrogram(spectrogram, f"Spectrogram with {win} Window", sr, hop_length=n_fft // 4)

